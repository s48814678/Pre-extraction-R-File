{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4846b8-5e39-44e7-b2e3-862883556d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import shapely\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adf1bd-cf95-4086-8320-646ca8f77f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination\n",
    "feature_selection_counts = Counter()\n",
    "\n",
    "#Requires a set of 20 .csv files for both training and validation.\n",
    "#First column as target feature.\n",
    "for i in range(1, 21):\n",
    "    train_df = pd.read_csv(f\"training_df_1_{i}.csv\")\n",
    "    X_train = train_df.iloc[:, 1:]\n",
    "    y_train = train_df.iloc[:, 0]\n",
    "    #Classification parameters.\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=16)\n",
    "    #Select 10 features for full-feature model and 5 for chl-a model.\n",
    "    rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    selected_features = X_train.columns[rfe.support_]\n",
    "    feature_selection_counts.update(selected_features)\n",
    "\n",
    "# Show features most frequently selected\n",
    "top_features = feature_selection_counts.most_common()\n",
    "print(\"Top features across all RFE runs:\")\n",
    "for feature, count in top_features:\n",
    "    print(f\"{feature}: selected in {count}/20 runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7815523-bdd7-4428-8249-c4065742aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Gini importance for all features.\n",
    "\n",
    "# Store frequency of selection and total importance\n",
    "feature_selection_counts = Counter()\n",
    "feature_importance_sums = defaultdict(float)\n",
    "\n",
    "#Same model set-up as above\n",
    "for i in range(1, 21):\n",
    "    train_df = pd.read_csv(f\"training_df_1_{i}.csv\")\n",
    "    X_train = train_df.iloc[:, 1:]\n",
    "    y_train = train_df.iloc[:, 0]\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=16)\n",
    "    rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "    rfe.fit(X_train, y_train)\n",
    "\n",
    "    # Get selected features\n",
    "    selected_features = X_train.columns[rfe.support_]\n",
    "    feature_selection_counts.update(selected_features)\n",
    "\n",
    "    # Get Gini importances from the fitted estimator\n",
    "    importances = rfe.estimator_.feature_importances_\n",
    "    for feature, importance in zip(selected_features, importances):\n",
    "        feature_importance_sums[feature] += importance\n",
    "\n",
    "# Build summary table\n",
    "summary = []\n",
    "for feature in feature_selection_counts:\n",
    "    count = feature_selection_counts[feature]\n",
    "    total_importance = feature_importance_sums[feature]\n",
    "    avg_importance = total_importance / count\n",
    "    summary.append((feature, count, round(avg_importance, 4)))\n",
    "\n",
    "# Rank by inclusions, then importance\n",
    "summary_sorted = sorted(summary, key=lambda x: (-x[1], -x[2]))\n",
    "print(f\"{'Feature':<25} {'Selected (n)':<12} {'Avg Gini Importance'}\")\n",
    "for feature, count, avg_imp in summary_sorted:\n",
    "    print(f\"{feature:<25} {count:<12} {avg_imp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea98240-7188-4b87-863e-ae97acd63270",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_correctness = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10da981-94e9-4033-8366-e02b13c254b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate training and validation for 20 datasets, and return average results.\n",
    "f1_scores = []\n",
    "kappa_scores = []\n",
    "conf_matrices = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Loop through the 20 datasets\n",
    "for i in range(1, 21):\n",
    "    # Load training and validation data\n",
    "    train_path = f\"training_df_32_{i}.csv\"\n",
    "    val_path = f\"validation_df_32_{i}.csv\"\n",
    "\n",
    "    training_df = pd.read_csv(train_path, encoding='latin1')\n",
    "    validation_df = pd.read_csv(val_path, encoding='latin1')\n",
    "\n",
    "    column_names = training_df.columns.tolist()\n",
    "    model_variables = column_names[1:]\n",
    "    model_col_indices = [column_names.index(var_name) for var_name in model_variables]\n",
    "\n",
    "    # Define model consistent with RFE\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=16)\n",
    "    model.fit(training_df.iloc[:, model_col_indices], training_df.iloc[:, 0])\n",
    "\n",
    "    # Predict on validation dataset\n",
    "    predictions = model.predict(validation_df.iloc[:, model_col_indices])\n",
    "\n",
    "    for j in range(len(validation_df.iloc[:, 0].astype(str))):\n",
    "            depth = validation_df.iloc[j]['Depth']\n",
    "            true_val = validation_df.iloc[j, 0]\n",
    "            pred_val = predictions[j]\n",
    "            correct = int(pred_val == true_val)\n",
    "            sample_correctness[depth].append(correct)\n",
    "\n",
    "    # Generate metrics\n",
    "    acc = accuracy_score(validation_df.iloc[:, 0], predictions)\n",
    "    f1 = f1_score(validation_df.iloc[:, 0], predictions, average='weighted')\n",
    "    kappa = cohen_kappa_score(validation_df.iloc[:, 0], predictions)\n",
    "    cm = confusion_matrix(validation_df.iloc[:, 0], predictions)\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "    kappa_scores.append(kappa)\n",
    "    conf_matrices.append(cm)\n",
    "\n",
    "# Average confusion matrices\n",
    "conf_matrices = np.array(conf_matrices)\n",
    "mean_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "# Summarise metrics\n",
    "results_summary = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'F1 Score (weighted)', 'Cohen Kappa'],\n",
    "    'Mean': [\n",
    "        np.mean(accuracy_scores),\n",
    "        np.mean(f1_scores),\n",
    "        np.mean(kappa_scores)\n",
    "    ],\n",
    "    'StdDev': [\n",
    "        np.std(accuracy_scores),\n",
    "        np.std(f1_scores),\n",
    "        np.std(kappa_scores)\n",
    "    ]\n",
    "})\n",
    "\n",
    "#Output metrics and confusion matrix\n",
    "print(\"=== Performance Metrics (Mean Â± SD) ===\")\n",
    "print(results_summary.round(4))\n",
    "print(\"\\n=== Mean Confusion Matrix ===\")\n",
    "print(mean_conf_matrix.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b9b3e-a402-4457-ab27-a677043e6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix normalised by row\n",
    "class_labels = sorted(np.unique(validation_df.iloc[:, 0]))\n",
    "mean_conf_matrix_row_norm = mean_conf_matrix / mean_conf_matrix.sum(axis=1, keepdims=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=mean_conf_matrix_row_norm, display_labels=class_labels)\n",
    "disp.plot(cmap='cividis', values_format=\".2f\")\n",
    "plt.title(\"Mean Confusion Matrix Normalised by Row\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_row_chla.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52232d34-c8e6-447d-81c6-d382035f0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix normalised by column\n",
    "class_labels = sorted(np.unique(validation_df.iloc[:, 0]))\n",
    "mean_conf_matrix_col_norm = mean_conf_matrix / mean_conf_matrix.sum(axis=0, keepdims=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=mean_conf_matrix_col_norm, display_labels=class_labels)\n",
    "disp.plot(cmap='cividis', values_format=\".2f\")\n",
    "plt.title(\"Mean Confusion Matrix Normalised by Column\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_col_chla.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
